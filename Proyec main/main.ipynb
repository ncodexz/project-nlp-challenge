{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7802b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nazb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Block 0: Importing Libraries\n",
    "\n",
    "# Data Manipulation & Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Processing & NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Machine Learning & Model Evaluation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Configurations\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK stopwords (only once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3225a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title  \\\n",
      "0      1  As U.S. budget fight looms, Republicans flip t...   \n",
      "1      1  U.S. military to accept transgender recruits o...   \n",
      "2      1  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3      1  FBI Russia probe helped by Australian diplomat...   \n",
      "4      1  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "2  December 31, 2017   \n",
      "3  December 30, 2017   \n",
      "4  December 29, 2017   \n",
      "\n",
      " Number of columns and rows: (39942, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39942 entries, 0 to 39941\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    39942 non-null  int64 \n",
      " 1   title    39942 non-null  object\n",
      " 2   text     39942 non-null  object\n",
      " 3   subject  39942 non-null  object\n",
      " 4   date     39942 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "\n",
      " Missing values per column: label      0\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "dtype: int64\n",
      "\n",
      " Class distribution: label\n",
      "1    19999\n",
      "0    19943\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Class distribution percentage:  label\n",
      "1    50.070102\n",
      "0    49.929898\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " Subject distribution: subject\n",
      "politicsNews       11272\n",
      "News                9050\n",
      "worldnews           8727\n",
      "politics            6841\n",
      "left-news           2482\n",
      "Government News     1570\n",
      "Name: count, dtype: int64\n",
      "Cross count of subject and label:\n",
      "label               0      1\n",
      "subject                     \n",
      "Government News  1570      0\n",
      "News             9050      0\n",
      "left-news        2482      0\n",
      "politics         6841      0\n",
      "politicsNews        0  11272\n",
      "worldnews           0   8727\n",
      "\n",
      "Percentage of fake/real per subject:\n",
      "label                0      1\n",
      "subject                      \n",
      "Government News  100.0    0.0\n",
      "News             100.0    0.0\n",
      "left-news        100.0    0.0\n",
      "politics         100.0    0.0\n",
      "politicsNews       0.0  100.0\n",
      "worldnews          0.0  100.0\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Load and explore dataset\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/Users/nazb/VSCode101/project-nlp-challenge/dataset/data.csv')\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Display dataset general information\n",
    "print( f'\\n Number of columns and rows:' ,df.shape)\n",
    "print (df.info())\n",
    "print(f'\\n Missing values per column:' ,df.isnull().sum())\n",
    "# Display the distribution of classes\n",
    "print(f'\\n Class distribution:' ,df[\"label\"].value_counts())\n",
    "print(f'\\n Class distribution percentage: ', df['label'].value_counts(normalize=True) * 100)\n",
    "# Display the distribution of subjects\n",
    "print(f'\\n Subject distribution:' ,df[\"subject\"].value_counts())\n",
    "# Cross count of subject vs label\n",
    "print(f\"Cross count of subject and label:\\n{df.groupby(['subject','label']).size().unstack(fill_value=0)}\\n\")\n",
    "print(f\"Percentage of fake/real per subject:\\n{df.groupby(['subject','label']).size().unstack(fill_value=0).div(df.groupby(['subject','label']).size().unstack(fill_value=0).sum(axis=1), axis=0) * 100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704384db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Data preprocessing\n",
    "\n",
    "# Initialize stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Concatenate title and text\n",
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "# Function to find acronyms with dots (e.g., U.S., F.B.I.)\n",
    "def find_dot_acronyms(df):\n",
    "    all_text = ' '.join(df['content'].astype(str))\n",
    "    pattern = r'\\b(?:[A-Z]\\.){2,}'  # two or more capital letters followed by dots\n",
    "    acronyms_with_dots = re.findall(pattern, all_text)\n",
    "    return set(acronyms_with_dots)\n",
    "\n",
    "# Get acronyms found in the dataset\n",
    "acronyms = find_dot_acronyms(df)\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    # Replace acronyms with dots by their version without dots\n",
    "    for abbr in acronyms:\n",
    "        replacement = abbr.replace('.', '')\n",
    "        text = text.replace(abbr, replacement)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove all characters that are not letters or spaces\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the content column\n",
    "df['clean_text'] = df['content'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c3bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/nazb/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/nazb/nltk_data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Descargar recursos (solo primera vez)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momw-1.4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Inicializar lemmatizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/nltk/downloader.py:774\u001b[0m, in \u001b[0;36mDownloader.download\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow\u001b[39m(s, prefix2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    766\u001b[0m     print_to(\n\u001b[1;32m    767\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mfill(\n\u001b[1;32m    768\u001b[0m             s,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    771\u001b[0m         )\n\u001b[1;32m    772\u001b[0m     )\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincr_download(info_or_id, download_dir, force):\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# Error messages\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, ErrorMessage):\n\u001b[1;32m    777\u001b[0m         show(msg\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/nltk/downloader.py:642\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[0;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m FinishCollectionMessage(info)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;66;03m# Handle Packages (delegate to a helper function).\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_package(info, download_dir, force)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/nltk/downloader.py:706\u001b[0m, in \u001b[0;36mDownloader._download_package\u001b[0;34m(self, info, download_dir, force)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m ProgressMessage(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m     infile \u001b[38;5;241m=\u001b[39m urlopen(info\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m    708\u001b[0m         num_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, info\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/urllib/request.py:189\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, context)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/urllib/request.py:489\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    486\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    488\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 489\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    492\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/urllib/request.py:506\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    505\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 506\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    507\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/urllib/request.py:466\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    465\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 466\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/urllib/request.py:1367\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[1;32m   1368\u001b[0m                         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/urllib/request.py:1323\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1323\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:1430\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1430\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lemmatization Optional Part\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Descargar recursos (solo primera vez)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Inicializar lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Función de lematización simple\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Aplicar a tu texto ya limpio\n",
    "print(\"Aplicando lematización...\")\n",
    "df['lemmatized_text'] = df['clean_text'].apply(lemmatize_text)\n",
    "\n",
    "# Ver ejemplo\n",
    "print(\"\\nAntes:\", df['clean_text'].iloc[0][:100])\n",
    "print(\"Después:\", df['lemmatized_text'].iloc[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9ac396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Senior U.S. Republican senator: 'Let Mr. Mueller do his job' WASHINGTON (Reuters) - The special counsel investigation of links between Russia and President Trump’s 2016 election campaign should continue without interference in 2018, despite calls from some Trump administration allies and Republican lawmakers to shut it down, a prominent Republican senator said on Sunday. Lindsey Graham, who serves on the Senate armed forces and judiciary committees, said Department of Justice Special Counsel Robert Mueller needs to carry on with his Russia investigation without political interference. “This investigation will go forward. It will be an investigation conducted without political influence,” Graham said on CBS’s Face the Nation news program. “And we all need to let Mr. Mueller do his job. I think he’s the right guy at the right time.”  The question of how Russia may have interfered in the election, and how Trump’s campaign may have had links with or co-ordinated any such effort, has loomed over the White House since Trump took office in January. It shows no sign of receding as Trump prepares for his second year in power, despite intensified rhetoric from some Trump allies in recent weeks accusing Mueller’s team of bias against the Republican president. Trump himself seemed to undercut his supporters in an interview last week with the New York Times in which he said he expected Mueller was “going to be fair.”    Russia’s role in the election and the question of possible links to the Trump campaign are the focus of multiple inquiries in Washington. Three committees of the Senate and the House of Representatives are investigating, as well as Mueller, whose team in May took over an earlier probe launched by the U.S. Federal Bureau of Investigation (FBI). Several members of the Trump campaign and administration have been convicted or indicted in the investigation.  Trump and his allies deny any collusion with Russia during the campaign, and the Kremlin has denied meddling in the election. Graham said he still wants an examination of the FBI’s use of a dossier on links between Trump and Russia that was compiled by a former British spy, Christopher Steele, which prompted Trump allies and some Republicans to question Mueller’s inquiry.   On Saturday, the New York Times reported that it was not that dossier that triggered an early FBI probe, but a tip from former Trump campaign foreign policy adviser George Papadopoulos to an Australian diplomat that Russia had damaging information about former Trump rival Hillary Clinton.  “I want somebody to look at the way the Department of Justice used this dossier. It bothers me greatly the way they used it, and I want somebody to look at it,” Graham said. But he said the Russia investigation must continue. “As a matter of fact, it would hurt us if we ignored it,” he said. \n",
      "\n",
      "Cleaned text:\n",
      "senior us republican senator let mr mueller job washington reuters special counsel investigation links russia president trump election campaign continue without interference despite calls trump administration allies republican lawmakers shut prominent republican senator said sunday lindsey graham serves senate armed forces judiciary committees said department justice special counsel robert mueller needs carry russia investigation without political interference investigation go forward investigation conducted without political influence graham said cbs face nation news program need let mr mueller job think right guy right time question russia may interfered election trump campaign may links co ordinated effort loomed white house since trump took office january shows sign receding trump prepares second year power despite intensified rhetoric trump allies recent weeks accusing mueller team bias republican president trump seemed undercut supporters interview last week new york times said expected mueller going fair russia role election question possible links trump campaign focus multiple inquiries washington three committees senate house representatives investigating well mueller whose team may took earlier probe launched us federal bureau investigation fbi several members trump campaign administration convicted indicted investigation trump allies deny collusion russia campaign kremlin denied meddling election graham said still wants examination fbi use dossier links trump russia compiled former british spy christopher steele prompted trump allies republicans question mueller inquiry saturday new york times reported dossier triggered early fbi probe tip former trump campaign foreign policy adviser george papadopoulos australian diplomat russia damaging information former trump rival hillary clinton want somebody look way department justice used dossier bothers greatly way used want somebody look graham said said russia investigation must continue matter fact would hurt us ignored said\n"
     ]
    }
   ],
   "source": [
    "# Check cleaning function\n",
    "example_text = df.loc[2, 'content']\n",
    "print(\"Original text:\")\n",
    "print(example_text)\n",
    "\n",
    "# Apply cleaning\n",
    "clean_example = clean_text(example_text)\n",
    "print(\"\\nCleaned text:\")\n",
    "print(clean_example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f845a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (39942, 20000)\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Vectorization\n",
    "    \n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,   # maximum number of features\n",
    "    ngram_range=(1,2),    # unigrams and bigrams\n",
    "    min_df=5,             # ignore words that appear in fewer than 5 documents\n",
    "    stop_words=None       # stopwords already removed\n",
    ")\n",
    "\n",
    "# Fit and transform the clean text to TF-IDF features\n",
    "X = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Check the shape of the resulting matrix\n",
    "print(\"TF-IDF matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90481ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cross-validation \n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8316d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Cross-Validation Results\n",
      "Accuracy scores per fold: [0.95543873 0.95356115 0.95305458 0.95192789 0.95117677]\n",
      "Mean accuracy: 0.9530318227372352\n",
      "Standard deviation: 0.0014651824425785445\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation with Naive Bayes\n",
    "\n",
    "# Initialize Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Stratified K-Folds (5 folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "nb_scores = cross_val_score(nb_model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Results\n",
    "print(\"Naive Bayes Cross-Validation Results\")\n",
    "print(\"Accuracy scores per fold:\", nb_scores)\n",
    "print(\"Mean accuracy:\", nb_scores.mean())\n",
    "print(\"Standard deviation:\", nb_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2abe707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Results\n",
      "Accuracy scores per fold: [0.99086244 0.9901114  0.98635453 0.98823235 0.98760641]\n",
      "Mean accuracy: 0.9886334257927134\n",
      "Standard deviation: 0.0016469296302669535\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation with Logistic Regression\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Stratified K-Folds (5 folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "lr_scores = cross_val_score(lr_model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Results\n",
    "print(\"Logistic Regression Cross-Validation Results\")\n",
    "print(\"Accuracy scores per fold:\", lr_scores)\n",
    "print(\"Mean accuracy:\", lr_scores.mean())\n",
    "print(\"Standard deviation:\", lr_scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473fb82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Block 4: Save the TF-IDF vectorizer\n",
    "\n",
    "# Save the TF-IDF vectorizer for future use\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"TF-IDF vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c69d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (31953, 20000) (31953,)\n",
      "Test set shape: (7989, 20000) (7989,)\n"
     ]
    }
   ],
   "source": [
    "#Block 4: Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Target variable\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "# 80% training, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ddbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.0307 seconds\n",
      "Test set accuracy: 0.9509\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3989\n",
      "           1       0.95      0.95      0.95      4000\n",
      "\n",
      "    accuracy                           0.95      7989\n",
      "   macro avg       0.95      0.95      0.95      7989\n",
      "weighted avg       0.95      0.95      0.95      7989\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[3801  188]\n",
      " [ 204 3796]]\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate a Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "nb_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691383b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.5611 seconds\n",
      "Test set accuracy: 0.9875\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3989\n",
      "           1       0.99      0.99      0.99      4000\n",
      "\n",
      "    accuracy                           0.99      7989\n",
      "   macro avg       0.99      0.99      0.99      7989\n",
      "weighted avg       0.99      0.99      0.99      7989\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[3929   60]\n",
      " [  40 3960]]\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate a Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "# 'saga' solver is efficient for large datasets and supports L2 regularization\n",
    "lr_model = LogisticRegression(\n",
    "    solver='saga',    # efficient for large, sparse datasets\n",
    "    max_iter=1000,    # increase iterations to ensure convergence\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "lr_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Test set accuracy: {accuracy_lr:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1eba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Save models\n",
    "import joblib\n",
    "\n",
    "# Save Multinomial Naive Bayes model\n",
    "joblib.dump(nb_model, 'naive_bayes_model.pkl')\n",
    "\n",
    "# Save Logistic Regression model\n",
    "joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "\n",
    "print(\"Both models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a11c5371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved successfully for both models!\n",
      "\n",
      "--- Distribution of predictions ---\n",
      "Naive Bayes label counts:\n",
      "label_nb\n",
      "0    3144\n",
      "1    1812\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Logistic Regression label counts:\n",
      "label_lr\n",
      "0    3381\n",
      "1    1575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Agreement between models: 4639/4956 (93.60%)\n",
      "\n",
      "Number of disagreements: 317\n",
      "                                                 title  label_nb  label_lr\n",
      "179  Family of Australian woman fatally shot wants ...         0         1\n",
      "212  UK police release new image of jogger in Londo...         0         1\n",
      "226  More than 50 arrested for looting in Miami dur...         0         1\n",
      "240  Draining the swamp: Hard-hit Everglades town m...         0         1\n",
      "241  After Irma, a mixed journey home for Florida e...         0         1\n"
     ]
    }
   ],
   "source": [
    "# Block 5: Load validation dataset, preprocess, predict, and save results\n",
    "\n",
    "# Load validation dataset\n",
    "\n",
    "validation_df = pd.read_csv('/Users/nazb/VSCode101/project-nlp-challenge/dataset/validation_data.csv')\n",
    "\n",
    "# Load saved models and vectorizer\n",
    "nb_model = joblib.load('naive_bayes_model.pkl')\n",
    "lr_model = joblib.load('logistic_regression_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Set stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text, acronyms=None):\n",
    "    text = str(text).lower()\n",
    "    if acronyms:\n",
    "        for abbr in acronyms:\n",
    "            text = text.replace(abbr, abbr.replace('.', ''))\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Preprocess validation data\n",
    "validation_df['content'] = validation_df['title'] + ' ' + validation_df['text']\n",
    "\n",
    "# Find acronyms with dots\n",
    "all_text = ' '.join(validation_df['content'].astype(str))\n",
    "pattern = r'\\b(?:[A-Z]\\.){2,}'\n",
    "acronyms = set(re.findall(pattern, all_text))\n",
    "\n",
    "# Clean text\n",
    "validation_df['clean_text'] = validation_df['content'].apply(lambda x: clean_text(x, acronyms))\n",
    "\n",
    "\n",
    "# Transform text using TF-IDF\n",
    "X_validation = tfidf_vectorizer.transform(validation_df['clean_text'])\n",
    "\n",
    "# Predict labels with both models\n",
    "validation_df['label_nb'] = nb_model.predict(X_validation)\n",
    "validation_df['label_lr'] = lr_model.predict(X_validation)\n",
    "\n",
    "# Save predictions to CSV\n",
    "# Naive Bayes\n",
    "nb_df = validation_df.copy()\n",
    "nb_df['label'] = nb_df['label_nb']\n",
    "nb_df[['label', 'title', 'text', 'subject', 'date']].to_csv('validation_predictions_nb.csv', index=False)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_df = validation_df.copy()\n",
    "lr_df['label'] = lr_df['label_lr']\n",
    "lr_df[['label', 'title', 'text', 'subject', 'date']].to_csv('validation_predictions_lr.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved successfully for both models!\")\n",
    "\n",
    "\n",
    "# Mini-report: distribution and comparison\n",
    "\n",
    "print(\"\\n--- Distribution of predictions ---\")\n",
    "print(\"Naive Bayes label counts:\")\n",
    "print(validation_df['label_nb'].value_counts())\n",
    "print(\"\\nLogistic Regression label counts:\")\n",
    "print(validation_df['label_lr'].value_counts())\n",
    "\n",
    "# Compare both models\n",
    "validation_df['agreement'] = validation_df['label_nb'] == validation_df['label_lr']\n",
    "agreement_count = validation_df['agreement'].sum()\n",
    "total_count = len(validation_df)\n",
    "print(f\"\\nAgreement between models: {agreement_count}/{total_count} ({agreement_count/total_count:.2%})\")\n",
    "\n",
    "# Optional: check disagreements\n",
    "disagreements = validation_df[validation_df['agreement'] == False][['title', 'label_nb', 'label_lr']]\n",
    "print(f\"\\nNumber of disagreements: {len(disagreements)}\")\n",
    "if len(disagreements) > 0:\n",
    "    print(disagreements.head(5))  # show first 5 examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d15e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final submission file saved: validation_predictions_FINAL.csv\n",
      "\n",
      "==================================================\n",
      "ACCURACY ESTIMATION REPORT\n",
      "==================================================\n",
      "\n",
      "Model Performance on Test Set:\n",
      "  Logistic Regression: 98.75% accuracy\n",
      "  Naive Bayes: 95.09% accuracy\n",
      "\n",
      "Expected Performance on Validation Data:\n",
      "  Estimated Accuracy: 98.0-99.0%\n",
      "  Confidence: High - models show consistent performance\n",
      "  Selected Model: Logistic Regression\n",
      "\n",
      "Validation Predictions Distribution:\n",
      "  Class 0 (Fake): 3381 samples\n",
      "  Class 1 (Real): 1575 samples\n",
      "\n",
      "Model Agreement Analysis:\n",
      "  Models agree on: 4639/4956 (93.6%) samples\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# GENERATE FINAL SUBMISSION FILE\n",
    "# ------------------------------\n",
    "\n",
    "# Use Logistic Regression (better performance - 98.75% vs 95.09%)\n",
    "final_output = validation_df[['title', 'text', 'subject', 'date']].copy()\n",
    "final_output['label'] = validation_df['label_lr']  # Using best model\n",
    "\n",
    "# Save final predictions\n",
    "final_output.to_csv('validation_predictions_FINAL.csv', index=False)\n",
    "print(\"Final submission file saved: validation_predictions_FINAL.csv\")\n",
    "\n",
    "# ------------------------------\n",
    "# ACCURACY ESTIMATION REPORT\n",
    "# ------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ACCURACY ESTIMATION REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nModel Performance on Test Set:\")\n",
    "print(f\"  Logistic Regression: 98.75% accuracy\")\n",
    "print(f\"  Naive Bayes: 95.09% accuracy\")\n",
    "\n",
    "print(f\"\\nExpected Performance on Validation Data:\")\n",
    "print(f\"  Estimated Accuracy: 98.0-99.0%\")\n",
    "print(f\"  Confidence: High - models show consistent performance\")\n",
    "print(f\"  Selected Model: Logistic Regression\")\n",
    "\n",
    "print(f\"\\nValidation Predictions Distribution:\")\n",
    "print(f\"  Class 0 (Fake): {sum(validation_df['label_lr'] == 0)} samples\")\n",
    "print(f\"  Class 1 (Real): {sum(validation_df['label_lr'] == 1)} samples\")\n",
    "\n",
    "print(f\"\\nModel Agreement Analysis:\")\n",
    "agreement = sum(validation_df['label_nb'] == validation_df['label_lr'])\n",
    "total = len(validation_df)\n",
    "print(f\"  Models agree on: {agreement}/{total} ({agreement/total:.1%}) samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
